# -*- coding: utf-8 -*-
"""GeldashAV_Lab2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kdekx5_f_msYft1n54iqaN7r9gqFQ4D_
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import os
import keras
from keras import layers
from keras.utils import to_categorical
from keras.datasets import mnist # subroutines for fetching the MNIST dataset
from keras.models import Model # basic class for specifying and training a neural network
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.callbacks import ModelCheckpoint
from keras.models import model_from_json
from keras import backend as K
import matplotlib.pyplot as plt
import seaborn as sns

# %matplotlib inline

train = pd.read_csv('train.csv') # Загружаем тренировочные данные
test = pd.read_csv('test.csv') # Загружаем тестовые данные
sample_sub = pd.read_csv('sample_submission.csv') # Загружаем бланк ответов

train.info()

X_train = train.drop(labels = ["label"],axis = 1)
X_train = (X_train.values).astype('float32')
X_test = (test.values).astype('float32')

y_train = train["label"].values.astype('int32')
y_train= to_categorical(y_train, num_classes=10)

X_train = X_train / 255.0

test = test / 255.0

X_train = X_train.reshape(X_train.shape[0],28,28,1)
X_test = X_test.reshape(test.shape[0],28,28,1)

g = plt.imshow(X_train[3][:,:,0], cmap='gray')

for i in range(6, 9):
    plt.subplot(330 + (i+1))
    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))
    plt.title(y_train[i]);

X_train.shape

X_test.shape

num_train = X_train.shape[0]
num_tesr = X_test.shape[0]

X_val = X_train[-10000:]
y_val = y_train[-10000:]
X_train = X_train[:-10000]
y_train = y_train[:-10000]

X_train.shape

inputs = keras.Input(shape=(784,), name='digits')
x = layers.Dense(64, activation='relu', name='dense_1')(inputs)
x = layers.Dense(64, activation='relu', name='dense_2')(x)
outputs = layers.Dense(10, activation='softmax', name='predictions')(x)

model = keras.Model(inputs=inputs, outputs=outputs)

model.compile(optimizer=keras.optimizers.RMSprop(),  # Optimizer
              # Минимизируемая функция потерь
              loss=keras.losses.SparseCategoricalCrossentropy(),
              # Список метрик для мониторинга
              metrics=[keras.metrics.SparseCategoricalAccuracy()])

model_json = model.to_json()
with open("model.json", "w") as json_file:
    json_file.write(model_json)

X_train = X_train.reshape(-1, 784)
X_val = X_val.reshape(-1, 784)
X_test = X_test.reshape(-1, 784)

y_train = np.argmax(y_train, axis=1)
y_val = np.argmax(y_val, axis=1)

history = model.fit(X_train, y_train,
                    batch_size=64,
                    epochs=10,
                    # Мы передаем валидационные данные для
                    # мониторинга потерь и метрик на этих данных
                    # в конце каждой эпохи
                    validation_data=(X_val, y_val))
model.evaluate(X_val, y_val, verbose=1)

predictions = model.predict(X_test[:3])
print('размерность прогнозов:', predictions.shape)

y_pred = model.predict(X_val)
# Convert predictions classes to one hot vectors
y_pred_classes = np.argmax(y_pred,axis = 1)

# predict results
results = model.predict(test)

results = np.argmax(results,axis = 1)

results = pd.Series(results,name="Label")

submission = pd.concat([pd.Series(range(1,28001),name = "ImageId"),results],axis = 1)

submission.to_csv("cnn_mnist_datagen.csv",index=False)